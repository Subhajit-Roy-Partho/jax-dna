{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a simple optimization with `jax_md`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), \"../../..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "from pathlib import Path\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax_md\n",
    "import optax\n",
    "\n",
    "import jax_dna.energy.dna1 as jdna_energy\n",
    "import jax_dna.input.topology as jdna_top\n",
    "import jax_dna.input.trajectory as jdna_traj\n",
    "import jax_dna.losses.observable_wrappers as jdna_losses\n",
    "import jax_dna.observables as jdna_obs\n",
    "import jax_dna.simulators.jax_md as jdna_jaxmd\n",
    "import jax_dna.ui.loggers.jupyter as jupyter_logger\n",
    "import jax_dna.utils.types as jdna_types\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is will be similar to the simple simulation except we arr going to add a loss and optimize the parameters of the simulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = {\n",
    "    \"n_sim_steps\": 20_000,\n",
    "    \"n_opt_steps\": 25,\n",
    "    \"learning_rate\": 0.001,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "experiment_dir = Path(\"../../../data/sys-defs/simple-helix\")\n",
    "\n",
    "topology = jdna_top.from_oxdna_file(experiment_dir / \"sys.top\")\n",
    "initial_positions = (\n",
    "    jdna_traj.from_file(\n",
    "        experiment_dir / \"bound_relaxed.conf\",\n",
    "        topology.strand_counts,\n",
    "    )\n",
    "    .states[0]\n",
    "    .to_rigid_body()\n",
    ")\n",
    "\n",
    "experiment_config, energy_config = jdna_energy.default_configs()\n",
    "\n",
    "dt = experiment_config[\"dt\"]\n",
    "kT = experiment_config[\"kT\"]\n",
    "diff_coef = experiment_config[\"diff_coef\"]\n",
    "rot_diff_coef = experiment_config[\"rot_diff_coef\"]\n",
    "\n",
    "# These are special values for the jax_md simulator\n",
    "gamma = jax_md.rigid_body.RigidBody(\n",
    "    center=jnp.array([kT / diff_coef], dtype=jnp.float64),\n",
    "    orientation=jnp.array([kT / rot_diff_coef], dtype=jnp.float64),\n",
    ")\n",
    "mass = jax_md.rigid_body.RigidBody(\n",
    "    center=jnp.array([experiment_config[\"nucleotide_mass\"]], dtype=jnp.float64),\n",
    "    orientation=jnp.array([experiment_config[\"moment_of_inertia\"]], dtype=jnp.float64),\n",
    ")\n",
    "\n",
    "geometry = energy_config[\"geometry\"]\n",
    "transform_fn = functools.partial(\n",
    "    jdna_energy.Nucleotide.from_rigid_body,\n",
    "    com_to_backbone=geometry[\"com_to_backbone\"],\n",
    "    com_to_hb=geometry[\"com_to_hb\"],\n",
    "    com_to_stacking=geometry[\"com_to_stacking\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The jax_md simulator needs an energy function. We can use the default\n",
    "energy functions and configurations for dna1 simulations. For more\n",
    "information on energy functions and configurations, see the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_fn_configs = jdna_energy.default_energy_configs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example were only going to optimize the parameters that are\n",
    "associated with the Stacking energy function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = []\n",
    "for ec in energy_fn_configs:\n",
    "    params.append(\n",
    "        ec.opt_params if isinstance(ec, jdna_energy.StackingConfiguration) else {}\n",
    "    )\n",
    "# we're not going to optimize wrt the seq specific stacking weights\n",
    "for op in params:\n",
    "    if \"ss_stack_weights\" in op:\n",
    "        del op[\"ss_stack_weights\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_fns = jdna_energy.default_energy_fns()\n",
    "\n",
    "simulator = jdna_jaxmd.JaxMDSimulator(\n",
    "    energy_configs=energy_fn_configs,\n",
    "    energy_fns=energy_fns,\n",
    "    topology=topology,\n",
    "    simulator_params=jdna_jaxmd.StaticSimulatorParams(\n",
    "        seq=jnp.array(topology.seq),\n",
    "        mass=mass,\n",
    "        bonded_neighbors=topology.bonded_neighbors,\n",
    "        checkpoint_every=500,\n",
    "        dt=dt,\n",
    "        kT=kT,\n",
    "        gamma=gamma,\n",
    "    ),\n",
    "    space=jax_md.space.free(),\n",
    "    transform_fn=transform_fn,\n",
    "    simulator_init=jax_md.simulate.nvt_langevin,\n",
    "    neighbors=jdna_jaxmd.NoNeighborList(unbonded_nbrs=topology.unbonded_neighbors),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ObservableLossFn class is a convenience wrapper for computing the the\n",
    "loss of an observable. In this case, we are using the propeller twist and\n",
    "the loss is squared error. the ObservableLossFn class implements `__call__`\n",
    "that takes the output of the simulation, the target, and weights and\n",
    "returns the loss and the measured observable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = jdna_losses.ObservableLossFn(\n",
    "    observable=jdna_obs.propeller.PropellerTwist(\n",
    "        rigid_body_transform_fn=transform_fn,\n",
    "        h_bonded_base_pairs=jnp.array([[1, 14], [2, 13], [3, 12], [4, 11], [5, 10], [6, 9]])\n",
    "    ),\n",
    "    loss_fn=jdna_losses.RootMeanSquaredError(),\n",
    "    return_observable=True,\n",
    ")\n",
    "\n",
    "# we're going to ignore the first 10% of the simulation steps for the loss calculation\n",
    "eq_steps = int(run_config[\"n_sim_steps\"] * 0.1)\n",
    "other_steps = run_config[\"n_sim_steps\"] - eq_steps\n",
    "weights = jnp.concat([\n",
    "    jnp.zeros(eq_steps, dtype=jnp.float64),\n",
    "    jnp.ones(other_steps, dtype=jnp.float64)/other_steps\n",
    "])\n",
    "\n",
    "# target_prop_twist = jnp.array(jdna_obs.propeller.TARGETS[\"oxDNA\"], dtype=jnp.float64)\n",
    "target_prop_twist = jnp.array(20.0, dtype=jnp.float64)\n",
    "def graddable_loss(in_params:jdna_types.Params, in_key:jax.random.PRNGKey) -> tuple[float, tuple[float, jax.random.PRNGKey]]:\n",
    "    in_key, subkey = jax.random.split(in_key)\n",
    "    sim_out = simulator.run(in_params, initial_positions, run_config[\"n_sim_steps\"], subkey)\n",
    "    loss, ptwist = loss_fn(sim_out, target_prop_twist, weights)\n",
    "    return (loss, (ptwist, in_key))\n",
    "\n",
    "grad_fn = jax.jit(jax.value_and_grad(graddable_loss, has_aux=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryan/repos/jax-dna/examples/simple_optimizations/jaxmd/../../../jax_dna/ui/loggers/logger.py:33: UserWarning: `log_dir` not results might not be saved to disk.\n",
      "  warnings.warn(MISSING_LOGDIR_WANING, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "936e7344541d40e6a089d0471ad58f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Optimization Status'), HBox(children=(IntProgress(value=0, bar_style='info', descrâ€¦"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger = jupyter_logger.JupyterLogger(\n",
    "    simulators=[],\n",
    "    observables=[],\n",
    "    objectives=[],\n",
    "    metrics_to_log=[\"loss\", [\"prop_twist\", \"target_ptwist\"]],# + params_to_log,\n",
    "    max_opt_steps=run_config[\"n_opt_steps\"],\n",
    "    plots_size_px=(600, 1200),\n",
    "    plots_nrows_ncols = (2, 1)\n",
    ")\n",
    "logger.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(1234)\n",
    "optimizer = optax.adam(learning_rate=run_config[\"learning_rate\"])\n",
    "opt_state = optimizer.init(params)\n",
    "\n",
    "for i in range(run_config[\"n_opt_steps\"]):\n",
    "    (loss, (prop_twist, _)), grads = grad_fn(params, key)\n",
    "\n",
    "    logger.log_metric(\"loss\", loss, i)\n",
    "    logger.log_metric(\"prop_twist\", prop_twist, i)\n",
    "    logger.log_metric(\"target_ptwist\", target_prop_twist, i)\n",
    "\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    logger.increment_prog_bar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
